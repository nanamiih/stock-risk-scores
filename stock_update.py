import pandas as pd
import requests, re, time
from openpyxl import Workbook
from bs4 import BeautifulSoup

# -------------------------------------------------------
# å…¬å¸ä»£ç¢¼èˆ‡å°æ‡‰åç¨±
# -------------------------------------------------------
TICKERS = {
    "AA": {"name": "Alcoa", "url": "https://stockanalysis.com/stocks/aa/financials/ratios/"},
    "RIO": {"name": "Rio Tinto", "url": "https://stockanalysis.com/stocks/rio/financials/ratios/"},
    "NHY": {"name": "Norsk Hydro", "url": "https://stockanalysis.com/quote/osl/NHY/financials/ratios/"},  # âœ… æ­æ´²å¸‚å ´
    "RS": {"name": "Reliance Steel & Aluminum", "url": "https://stockanalysis.com/stocks/rs/financials/ratios/"},
    "KALU": {"name": "Kaiser Aluminum", "url": "https://stockanalysis.com/stocks/kalu/financials/ratios/"},
    "RYI": {"name": "Ryerson Holding", "url": "https://stockanalysis.com/stocks/ryi/financials/ratios/"}
}

TARGET = {
    "EBITDA": "EBITDA",
    "Debt": "Debt / Equity Ratio",
    "Inventory Turnover": "Inventory Turnover",
    "Current Ratio": "Current Ratio"
}


# -------------------------------------------------------
# è²¡å ±æ¯”ç‡çˆ¬å–ï¼ˆæ”¯æ´ quote/oslï¼‰
# -------------------------------------------------------
def fetch_ratios(symbol, url):
    headers = {"User-Agent": "Mozilla/5.0"}
    html = None

    # Retry up to 5 times
    for attempt in range(5):
        try:
            r = requests.get(url, headers=headers, timeout=25)
            if r.status_code == 200 and "<table" in r.text:
                html = r.text
                break
            print(f"âš ï¸ {symbol}: ç¬¬ {attempt+1} æ¬¡å˜—è©¦å¤±æ•— {url}")
        except Exception as e:
            print(f"âš ï¸ {symbol}: å˜—è©¦å¤±æ•— ({e})")
        time.sleep(5)

    if not html:
        print(f"âŒ {symbol}: æ‰€æœ‰é é¢éƒ½ç„¡æ³•å–å¾—è¡¨æ ¼")
        return None

    # å˜—è©¦ç”¨ pandas è®€å–
    try:
        tables = pd.read_html(html)
    except Exception:
        tables = []

    # å¦‚æœ pandas æŠ“ä¸åˆ°ï¼Œç”¨ BeautifulSoup
    if not tables:
        soup = BeautifulSoup(html, "html.parser")
        raw_table = soup.find("table")
        tables = [pd.read_html(str(raw_table))[0]] if raw_table else []

    if not tables:
        print(f"âš ï¸ {symbol}: æ‰¾ä¸åˆ°è¡¨æ ¼")
        return None

    df = tables[0].copy()

    # å£“å¹³å¤šå±¤æ¨™é¡Œ
    if isinstance(df.columns, pd.MultiIndex):
        df.columns = [
            " ".join([str(c) for c in col if c and c != "nan"]).strip()
            for col in df.columns
        ]

    df.rename(columns={df.columns[0]: "Metric"}, inplace=True)

    # ç¯©é¸ç›®æ¨™æ¬„ä½
    df = df[df["Metric"].str.contains("|".join(TARGET.keys()), case=False, na=False)]
    df["Metric"] = df["Metric"].apply(
        lambda x: next((v for k, v in TARGET.items() if k.lower() in x.lower()), x)
    )

    # è½‰ç½®è¡¨æ ¼
    df = df.set_index("Metric").T.reset_index().rename(columns={"index": "Date_1"})

   # æ—¥æœŸæ¸…ç†ï¼ˆä¿æŒ YYYY/MM/DDï¼‰
    from datetime import datetime
    
    def clean_date(x):
        x = str(x)
        
        # å˜—è©¦è§£æå®Œæ•´è‹±æ–‡æ—¥æœŸï¼ˆä¾‹: Oct 25 2025ï¼‰
        m = re.search(r"([A-Za-z]{3,9}\s\d{1,2}\s\d{4})", x)
        if m:
            try:
                return pd.to_datetime(m.group(1)).strftime("%Y/%m/%d")
            except:
                pass
    
        today_str = datetime.today().strftime("%Y/%m/%d")
        m = re.search(r"(\d{4})", x)
        
        # è‹¥æ˜¯"Current"ã€"TTM"ã€"Oct"ã€"Sep"ç­‰ â†’ ä½¿ç”¨ä»Šå¤©æ—¥æœŸ
        if any(k in x for k in ["Current", "TTM", "Oct", "Sep"]):
            return today_str
        elif m:
            return f"{m.group(1)}/12/31"
        else:
            return today_str

    df["Date_1"] = df["Date_1"].apply(clean_date)
    df = df.loc[:, ~df.columns.duplicated()].fillna("")
    return df


# -------------------------------------------------------
# æŠ“å– Z/F Scoreï¼ˆæ”¯æ´ quote/osl/NHYï¼‰
# -------------------------------------------------------
def fetch_scores(symbol):
    if symbol == "NHY":
        url = "https://stockanalysis.com/quote/osl/NHY/statistics/"
    else:
        url = f"https://stockanalysis.com/stocks/{symbol.lower()}/statistics/"

    headers = {"User-Agent": "Mozilla/5.0"}
    try:
        r = requests.get(url, headers=headers, timeout=20)
        if r.status_code != 200:
            return {"Altman Z-Score": "", "Piotroski F-Score": ""}
        df = pd.concat(pd.read_html(r.text), ignore_index=True)
        df.columns = ["Metric", "Value"]
        z = df[df["Metric"].str.contains("Altman Z", na=False)]["Value"].values
        f = df[df["Metric"].str.contains("Piotroski F", na=False)]["Value"].values
        return {
            "Altman Z-Score": z[0] if len(z) else "",
            "Piotroski F-Score": f[0] if len(f) else ""
        }
    except Exception:
        return {"Altman Z-Score": "", "Piotroski F-Score": ""}


# -------------------------------------------------------
# å¯«å…¥ Excel
# -------------------------------------------------------
wb = Workbook()
wb.remove(wb.active)

for t, info in TICKERS.items():
    print(f"ğŸ” æŠ“å– {info['name']} ({t}) ...")
    ratios = fetch_ratios(t, info["url"])
    scores = fetch_scores(t)

    if ratios is None or ratios.empty:
        ratios = pd.DataFrame(columns=["Date_1", "EBITDA", "Debt / Equity Ratio",
                                       "Inventory Turnover", "Current Ratio"])
        print(f"âš ï¸ {info['name']}: ç„¡è³‡æ–™ï¼Œå»ºç«‹ç©ºç™½é ã€‚")

    ratios["Ticker"] = t
    ratios["Altman Z-Score"] = scores.get("Altman Z-Score", "")
    ratios["Piotroski F-Score"] = scores.get("Piotroski F-Score", "")

    # å›ºå®šæ¬„ä½é †åº
    final_cols = [
        "Date_1", "EBITDA", "Debt / Equity Ratio",
        "Inventory Turnover", "Current Ratio",
        "Ticker", "Altman Z-Score", "Piotroski F-Score"
    ]
    ratios = ratios[[c for c in final_cols if c in ratios.columns]]

    sheet = wb.create_sheet(title=info["name"][:30])
    sheet.append(ratios.columns.tolist())
    for row in ratios.itertuples(index=False):
        sheet.append(["" if pd.isna(x) else x for x in row])

    print(f"âœ… {info['name']} å®Œæˆ")

wb.save("Stock_Risk_Scores.xlsx")
print("âœ… å·²è¼¸å‡º Stock_Risk_Scores.xlsx âœ…")
